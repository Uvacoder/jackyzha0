<!DOCTYPE html>
<html lang="en">
<head>
    
    <meta charset="UTF-8">
    <meta name="description" content="How do we tell that this is a “valid” intent?">
    <title>reflect: NLP Model Explained</title>
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="shortcut icon" type="image/png" href="/res/logo.png" />

    
    <meta property="og:url" content="https://jzhao.xyz" />
    <meta property="og:title" content="" />
    <meta property="og:description" content="" />
    <meta property="og:image" content="https://jzhao.xyz/res/og-card.png" />
    <meta name="twitter:card" content="summary_large_image">
    <meta name="twitter:creator" content="@_jzhao">
    <meta name="twitter:title" content="">
    <meta name="twitter:description" content="" />
    <meta name="twitter:image" content="https://jzhao.xyz/res/og-card.png" />

    
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;600;700&family=Spectral:wght@400;600;700&family=JetBrains+Mono:wght@400;700&display=swap" rel="stylesheet">
    
    
    
    
    <style>
        :root{--lt-colours-light:var(--light) !important;--lt-colours-lightgray:var(--lightgray) !important;--lt-colours-dark:var(--secondary) !important;--lt-colours-secondary:var(--tertiary) !important;--lt-colours-gray:var(--outlinegray) !important}body{position:relative}@keyframes fadeIn{0%{opacity:0}100%{opacity:1}}.return-only{display:none}[visited=true] .return-only{display:inline}[show-animation=true] .delay{animation:fadeIn ease .5s;opacity:0;animation-fill-mode:forwards}[show-animation=true] .delay.t-1{animation-delay:.5s}[show-animation=true] .delay.t-2{animation-delay:.9s}[show-animation=true] .delay.t-3{animation-delay:2s}[show-animation=true] .delay.t-4{animation-delay:2.2s}[show-animation=true] .delay.stagger:nth-last-of-type(1)>*:nth-child(1){animation:fadeIn ease .5s;opacity:0;animation-fill-mode:forwards;animation-delay:2.28s;z-index:19;position:relative}[show-animation=true] .delay.stagger:nth-last-of-type(1)>*:nth-child(2){animation:fadeIn ease .5s;opacity:0;animation-fill-mode:forwards;animation-delay:2.36s;z-index:18;position:relative}[show-animation=true] .delay.stagger:nth-last-of-type(1)>*:nth-child(3){animation:fadeIn ease .5s;opacity:0;animation-fill-mode:forwards;animation-delay:2.44s;z-index:17;position:relative}[show-animation=true] .delay.stagger:nth-last-of-type(1)>*:nth-child(4){animation:fadeIn ease .5s;opacity:0;animation-fill-mode:forwards;animation-delay:2.52s;z-index:16;position:relative}[show-animation=true] .delay.stagger:nth-last-of-type(1)>*:nth-child(5){animation:fadeIn ease .5s;opacity:0;animation-fill-mode:forwards;animation-delay:2.6s;z-index:15;position:relative}[show-animation=true] .delay.stagger:nth-last-of-type(1)>*:nth-child(6){animation:fadeIn ease .5s;opacity:0;animation-fill-mode:forwards;animation-delay:2.68s;z-index:14;position:relative}[show-animation=true] .delay.stagger:nth-last-of-type(1)>*:nth-child(7){animation:fadeIn ease .5s;opacity:0;animation-fill-mode:forwards;animation-delay:2.76s;z-index:13;position:relative}[show-animation=true] .delay.stagger:nth-last-of-type(1)>*:nth-child(8){animation:fadeIn ease .5s;opacity:0;animation-fill-mode:forwards;animation-delay:2.84s;z-index:12;position:relative}[show-animation=true] .delay.stagger:nth-last-of-type(1)>*:nth-child(9){animation:fadeIn ease .5s;opacity:0;animation-fill-mode:forwards;animation-delay:2.92s;z-index:11;position:relative}[show-animation=true] .delay.stagger:nth-last-of-type(1)>*:nth-child(10){animation:fadeIn ease .5s;opacity:0;animation-fill-mode:forwards;animation-delay:3s;z-index:10;position:relative}[show-animation=true] .delay.stagger:nth-last-of-type(2)>*:nth-child(1){animation:fadeIn ease .5s;opacity:0;animation-fill-mode:forwards;animation-delay:2.28s;z-index:29;position:relative}[show-animation=true] .delay.stagger:nth-last-of-type(2)>*:nth-child(2){animation:fadeIn ease .5s;opacity:0;animation-fill-mode:forwards;animation-delay:2.36s;z-index:28;position:relative}[show-animation=true] .delay.stagger:nth-last-of-type(2)>*:nth-child(3){animation:fadeIn ease .5s;opacity:0;animation-fill-mode:forwards;animation-delay:2.44s;z-index:27;position:relative}[show-animation=true] .delay.stagger:nth-last-of-type(2)>*:nth-child(4){animation:fadeIn ease .5s;opacity:0;animation-fill-mode:forwards;animation-delay:2.52s;z-index:26;position:relative}[show-animation=true] .delay.stagger:nth-last-of-type(2)>*:nth-child(5){animation:fadeIn ease .5s;opacity:0;animation-fill-mode:forwards;animation-delay:2.6s;z-index:25;position:relative}[show-animation=true] .delay.stagger:nth-last-of-type(2)>*:nth-child(6){animation:fadeIn ease .5s;opacity:0;animation-fill-mode:forwards;animation-delay:2.68s;z-index:24;position:relative}[show-animation=true] .delay.stagger:nth-last-of-type(2)>*:nth-child(7){animation:fadeIn ease .5s;opacity:0;animation-fill-mode:forwards;animation-delay:2.76s;z-index:23;position:relative}[show-animation=true] .delay.stagger:nth-last-of-type(2)>*:nth-child(8){animation:fadeIn ease .5s;opacity:0;animation-fill-mode:forwards;animation-delay:2.84s;z-index:22;position:relative}[show-animation=true] .delay.stagger:nth-last-of-type(2)>*:nth-child(9){animation:fadeIn ease .5s;opacity:0;animation-fill-mode:forwards;animation-delay:2.92s;z-index:21;position:relative}[show-animation=true] .delay.stagger:nth-last-of-type(2)>*:nth-child(10){animation:fadeIn ease .5s;opacity:0;animation-fill-mode:forwards;animation-delay:3s;z-index:20;position:relative}[show-animation=true] .delay.stagger:nth-last-of-type(3)>*:nth-child(1){animation:fadeIn ease .5s;opacity:0;animation-fill-mode:forwards;animation-delay:2.28s;z-index:39;position:relative}[show-animation=true] .delay.stagger:nth-last-of-type(3)>*:nth-child(2){animation:fadeIn ease .5s;opacity:0;animation-fill-mode:forwards;animation-delay:2.36s;z-index:38;position:relative}[show-animation=true] .delay.stagger:nth-last-of-type(3)>*:nth-child(3){animation:fadeIn ease .5s;opacity:0;animation-fill-mode:forwards;animation-delay:2.44s;z-index:37;position:relative}[show-animation=true] .delay.stagger:nth-last-of-type(3)>*:nth-child(4){animation:fadeIn ease .5s;opacity:0;animation-fill-mode:forwards;animation-delay:2.52s;z-index:36;position:relative}[show-animation=true] .delay.stagger:nth-last-of-type(3)>*:nth-child(5){animation:fadeIn ease .5s;opacity:0;animation-fill-mode:forwards;animation-delay:2.6s;z-index:35;position:relative}[show-animation=true] .delay.stagger:nth-last-of-type(3)>*:nth-child(6){animation:fadeIn ease .5s;opacity:0;animation-fill-mode:forwards;animation-delay:2.68s;z-index:34;position:relative}[show-animation=true] .delay.stagger:nth-last-of-type(3)>*:nth-child(7){animation:fadeIn ease .5s;opacity:0;animation-fill-mode:forwards;animation-delay:2.76s;z-index:33;position:relative}[show-animation=true] .delay.stagger:nth-last-of-type(3)>*:nth-child(8){animation:fadeIn ease .5s;opacity:0;animation-fill-mode:forwards;animation-delay:2.84s;z-index:32;position:relative}[show-animation=true] .delay.stagger:nth-last-of-type(3)>*:nth-child(9){animation:fadeIn ease .5s;opacity:0;animation-fill-mode:forwards;animation-delay:2.92s;z-index:31;position:relative}[show-animation=true] .delay.stagger:nth-last-of-type(3)>*:nth-child(10){animation:fadeIn ease .5s;opacity:0;animation-fill-mode:forwards;animation-delay:3s;z-index:30;position:relative}[show-animation=true] .delay.stagger:nth-last-of-type(4)>*:nth-child(1){animation:fadeIn ease .5s;opacity:0;animation-fill-mode:forwards;animation-delay:2.28s;z-index:49;position:relative}[show-animation=true] .delay.stagger:nth-last-of-type(4)>*:nth-child(2){animation:fadeIn ease .5s;opacity:0;animation-fill-mode:forwards;animation-delay:2.36s;z-index:48;position:relative}[show-animation=true] .delay.stagger:nth-last-of-type(4)>*:nth-child(3){animation:fadeIn ease .5s;opacity:0;animation-fill-mode:forwards;animation-delay:2.44s;z-index:47;position:relative}[show-animation=true] .delay.stagger:nth-last-of-type(4)>*:nth-child(4){animation:fadeIn ease .5s;opacity:0;animation-fill-mode:forwards;animation-delay:2.52s;z-index:46;position:relative}[show-animation=true] .delay.stagger:nth-last-of-type(4)>*:nth-child(5){animation:fadeIn ease .5s;opacity:0;animation-fill-mode:forwards;animation-delay:2.6s;z-index:45;position:relative}[show-animation=true] .delay.stagger:nth-last-of-type(4)>*:nth-child(6){animation:fadeIn ease .5s;opacity:0;animation-fill-mode:forwards;animation-delay:2.68s;z-index:44;position:relative}[show-animation=true] .delay.stagger:nth-last-of-type(4)>*:nth-child(7){animation:fadeIn ease .5s;opacity:0;animation-fill-mode:forwards;animation-delay:2.76s;z-index:43;position:relative}[show-animation=true] .delay.stagger:nth-last-of-type(4)>*:nth-child(8){animation:fadeIn ease .5s;opacity:0;animation-fill-mode:forwards;animation-delay:2.84s;z-index:42;position:relative}[show-animation=true] .delay.stagger:nth-last-of-type(4)>*:nth-child(9){animation:fadeIn ease .5s;opacity:0;animation-fill-mode:forwards;animation-delay:2.92s;z-index:41;position:relative}[show-animation=true] .delay.stagger:nth-last-of-type(4)>*:nth-child(10){animation:fadeIn ease .5s;opacity:0;animation-fill-mode:forwards;animation-delay:3s;z-index:40;position:relative}[show-animation=true] .delay.stagger:nth-last-of-type(5)>*:nth-child(1){animation:fadeIn ease .5s;opacity:0;animation-fill-mode:forwards;animation-delay:2.28s;z-index:59;position:relative}[show-animation=true] .delay.stagger:nth-last-of-type(5)>*:nth-child(2){animation:fadeIn ease .5s;opacity:0;animation-fill-mode:forwards;animation-delay:2.36s;z-index:58;position:relative}[show-animation=true] .delay.stagger:nth-last-of-type(5)>*:nth-child(3){animation:fadeIn ease .5s;opacity:0;animation-fill-mode:forwards;animation-delay:2.44s;z-index:57;position:relative}[show-animation=true] .delay.stagger:nth-last-of-type(5)>*:nth-child(4){animation:fadeIn ease .5s;opacity:0;animation-fill-mode:forwards;animation-delay:2.52s;z-index:56;position:relative}[show-animation=true] .delay.stagger:nth-last-of-type(5)>*:nth-child(5){animation:fadeIn ease .5s;opacity:0;animation-fill-mode:forwards;animation-delay:2.6s;z-index:55;position:relative}[show-animation=true] .delay.stagger:nth-last-of-type(5)>*:nth-child(6){animation:fadeIn ease .5s;opacity:0;animation-fill-mode:forwards;animation-delay:2.68s;z-index:54;position:relative}[show-animation=true] .delay.stagger:nth-last-of-type(5)>*:nth-child(7){animation:fadeIn ease .5s;opacity:0;animation-fill-mode:forwards;animation-delay:2.76s;z-index:53;position:relative}[show-animation=true] .delay.stagger:nth-last-of-type(5)>*:nth-child(8){animation:fadeIn ease .5s;opacity:0;animation-fill-mode:forwards;animation-delay:2.84s;z-index:52;position:relative}[show-animation=true] .delay.stagger:nth-last-of-type(5)>*:nth-child(9){animation:fadeIn ease .5s;opacity:0;animation-fill-mode:forwards;animation-delay:2.92s;z-index:51;position:relative}[show-animation=true] .delay.stagger:nth-last-of-type(5)>*:nth-child(10){animation:fadeIn ease .5s;opacity:0;animation-fill-mode:forwards;animation-delay:3s;z-index:50;position:relative}h1,h2,h3,h4,ol,ul,thead{font-family:jetbrains mono;color:var(--dark);font-weight:revert;margin:revert;padding:revert}article h1,article h2,article h3,article h4,article h5{margin-top:1em;margin-bottom:-.5em}article p{margin-bottom:1.5em}p,ul,text,li,ol{font-family:spectral,sans-serif;color:var(--gray);fill:var(--gray);font-size:1.1rem;font-weight:revert;margin:revert;padding:revert}#TableOfContents>ol{counter-reset:section;margin-left:0;padding-left:1.5em}#TableOfContents>ol>li{counter-increment:section}#TableOfContents>ol>li>ol{counter-reset:subsection}#TableOfContents>ol>li>ol>li{counter-increment:subsection}#TableOfContents>ol>li>ol>li::marker{content:counter(section)"." counter(subsection)"  "}#TableOfContents>ol>li::marker{content:counter(section)"  "}#TableOfContents>ol>li::marker,#TableOfContents>ol>li>ol>li::marker{font-family:spectral;font-weight:700}footer{margin-top:4em;text-align:center}table{width:100%}img{width:100%;border-radius:3px;margin:1em 0}p>img+em{display:block;transform:translateY(-1em)}sup{line-height:0}p,tbody,li{font-family:Spectral;color:var(--gray);line-height:1.5em}blockquote{margin-left:0;border-left:3px solid var(--secondary);padding-left:1em;transition:border-color .2s ease}blockquote:hover{border-color:var(--tertiary)}table{padding:1.5em}td,th{padding:.1em .5em}.footnotes p{margin:.5em 0}.pagination{list-style:none;padding-left:0;display:flex;margin-top:2em;gap:1.5em;justify-content:center}.pagination>li{text-align:center;display:inline-block}.pagination>li a{background-color:transparent!important;font-family:jetbrains mono}.pagination>li a[href$="#"]{opacity:.2}.section h3>a{font-weight:700;font-family:jetbrains mono;margin:0}.section p{margin:.5em 0}.tags{list-style:none;padding-left:0;margin-bottom:1em}.tags .meta>h1{margin:0}.tags .meta>p{margin:0}.tags>li{display:inline-block}.tags>li>a{border-radius:8px;border:var(--outlinegray)1px solid;padding:.1em .3em}.tags>li>a::before{content:"#";margin-right:.3em;color:var(--outlinegray)}article{font-family:Spectral,serif}article>.meta{margin:-1.5em 0 1em;opacity:.7}article h1>a,article h2>a,article h3>a,article h4>a{font-family:jetbrains mono,monospace}article a{font-weight:600;font-family:Spectral,serif}article a.internal-link{text-decoration:none;background-color:rgba(143,159,169,.15);padding:0 .1em;margin:auto -.1em;border-radius:3px}.popover{position:absolute;width:17em;background-color:var(--light);padding:1em;border:1px solid var(--outlinegray);border-radius:5px;transform:translate(-50%,40%);opacity:0;display:inline-block;visibility:hidden;pointer-events:none;transition:opacity .2s ease,transform .2s ease;transition-delay:.3s;text-align:left;user-select:none;z-index:999}.popover.visible{visibility:visible;opacity:1;transform:translate(-50%,20%)}.popover>h3{font-size:1rem;margin:.25em 0}.popover>.meta{margin-top:.25em;opacity:.5;font-family:jetbrains mono,monospace;font-size:.8rem}.popover>p{margin:0;font-weight:400;user-select:none}.backlinks a{font-weight:600;font-size:.9rem}sup>a{text-decoration:none;padding:0 .1em 0 .2em}a{font-family:jetbrains mono,monospace;font-size:1em;font-weight:700;text-decoration:none;transition:all .2s ease;color:var(--secondary)}a:hover{color:var(--tertiary)!important}pre{font-family:jetbrains mono;padding:.75em;border-radius:3px;overflow-x:scroll}code{font-family:jetbrains mono;font-size:.85em;padding:.15em .3em;border-radius:5px;background:var(--lightgray)}html{scroll-behavior:smooth}body{margin:0;height:100vh;width:100vw;overflow-x:hidden;background-color:var(--light)}footer{margin-top:4em}footer>a{font-size:1em;color:var(--secondary);padding:0 .5em 3em}hr{overflow:visible;padding:0;margin:5em auto;border:none;border-top:1px solid var(--dark);color:var(--dark);text-align:center;width:40%}hr:after{content:"* * *";display:inline-block;margin:-1em 0 .5em;font-size:1.5em;padding:.5em 1em;background:var(--light);transform:translateY(-.1em)}.singlePage{margin:4em 30vw}@media all and (max-width:1200px){.singlePage{margin:25px 5vw}}.page-end{display:flex;flex-direction:row;gap:2em}@media all and (max-width:780px){.page-end{flex-direction:column}}.page-end>*{flex:1 0}.page-end>.backlinks-container>ul{list-style:none;padding-left:0}.page-end>.backlinks-container>ul>li{margin:.5em 0;padding:.25em 1em;border:var(--outlinegray)1px solid;border-radius:5px}.page-end #graph-container{border:var(--outlinegray)1px solid;border-radius:5px}.centered{margin-top:30vh}article>h1{font-size:2em}header{display:flex;flex-direction:row;align-items:center}header>h1{font-size:2em}@media all and (max-width:600px){header>nav{display:none}}header>.spacer{flex:auto}header>svg{cursor:pointer;width:18px;min-width:18px;margin:0 1em}header>svg:hover .search-path{stroke:var(--tertiary)}header>svg .search-path{stroke:var(--gray);stroke-width:2px;transition:stroke .5s ease}#search-container{position:fixed;z-index:9999;left:0;top:0;width:100vw;height:100%;overflow:scroll;display:none;backdrop-filter:blur(4px);-webkit-backdrop-filter:blur(4px)}#search-container>div{width:50%;margin-top:15vh;margin-left:auto;margin-right:auto}@media all and (max-width:1200px){#search-container>div{width:90%}}#search-container>div>*{width:100%;border-radius:4px;background:var(--light);box-shadow:0 14px 50px rgba(27,33,48,.12),0 10px 30px rgba(27,33,48,.16);margin-bottom:2em}#search-container>div>input{box-sizing:border-box;padding:.5em 1em;font-family:jetbrains mono,sans-serif;color:var(--dark);font-size:1.1em;border:1px solid var(--outlinegray)}#search-container>div>input:focus{outline:none}#search-container>div>#results-container>.result-card{padding:1em;cursor:pointer;transition:background .2s ease;border:1px solid var(--outlinegray);border-bottom:none;width:100%;font-family:inherit;font-size:100%;line-height:1.15;margin:0;overflow:visible;text-transform:none;text-align:left;background:var(--light);outline:none}#search-container>div>#results-container>.result-card:hover,#search-container>div>#results-container>.result-card:focus{background:rgba(180,180,180,.15)}#search-container>div>#results-container>.result-card:first-of-type{border-top-left-radius:5px;border-top-right-radius:5px}#search-container>div>#results-container>.result-card:last-of-type{border-bottom-left-radius:5px;border-bottom-right-radius:5px;border-bottom:1px solid var(--outlinegray)}#search-container>div>#results-container>.result-card>h3,#search-container>div>#results-container>.result-card>p{margin:0}#search-container>div>#results-container>.result-card .search-highlight{background-color:#afbfc966;padding:0 .2em;border-radius:3px}.section-ul{list-style:none;padding-left:0}.section-ul>li{border:1px solid var(--outlinegray);border-radius:5px;padding:0 1em;margin-bottom:1em}.section-ul>li h3{opacity:1;font-weight:700;margin-bottom:0}.section-ul>li .meta{opacity:.6}.postLi{margin:1.5em 0;list-style:none}.postLi .time{font-family:jetbrains mono;font-size:.8rem;margin:0}.postLi .singlePost{display:flex;flex-direction:row;align-items:center;justify-content:space-between}.postLi .singlePost *{margin:0 auto}.postLi .singlePost>.desc{flex:1}.postLi .singlePost>.desc>*{display:inline-block}.postLi .singlePost>.meta{margin-left:2em!important}
    </style>
    
    
    
    
    <style>
        :root{--light:#f2e9e1;--dark:#2f2235;--secondary:#426b69;--tertiary:#8db9b7;--visited:#8db9b7;--primary:#e46262;--gray:#3a333d;--lightgray:#e3deda;--outlinegray:#a8a39e}::selection,mark,:root::target-text{background:var(--tertiary);background-color:var(--tertiary)}[saved-theme=dark]{--light:#201624 !important;--dark:#faede1 !important;--secondary:#77a3a0 !important;--visited:#567d7b !important;--tertiary:#325452 !important;--primary:#bd6868 !important;--gray:#d4d4d4 !important;--lightgray:#4f473f !important;--outlinegray:#3b2842 !important}.ascii{margin-bottom:0;padding:0;white-space:pre;font-weight:700;font-family:jetbrains mono}.ascii.ascii-dark,.ascii .ascii-dark{color:var(--dark)}.ascii.ascii-gray,.ascii .ascii-gray{color:var(--outlinegray)}.ascii.ascii-primary,.ascii .ascii-primary{color:var(--primary)}.ascii.ascii-secondary,.ascii .ascii-secondary{color:var(--secondary)}.ascii.ascii-tertiary,.ascii .ascii-tertiary{color:var(--tertiary)}.banner{position:relative;width:100%;overflow-x:hidden;display:flex;justify-content:center}.index{margin:4em 25vw}@media all and (max-width:1200px){.index{margin:25px 5vw}}.index>.bio{display:flex;gap:1.5em}@media screen and (max-width:1440px){.index>.bio{flex-direction:column!important}}.index>.bio>ul{flex:0 0 30%;list-style:none;padding:0;margin-left:0;z-index:0}.index>.bio>ul h2{font-size:1.4rem;margin:0 0 1em}.index>.bio>ul a{font-family:Spectral}.index>.bio>ul li{margin-bottom:.5em}.index>.bio>ul h3{margin:0}.index>.bio>ul .meta{margin-top:0}.index>.bio>ul .tags>li>a{font-size:.8em;font-weight:400}
    </style>
    
    
    
    
    <style>
        .darkmode{float:right;padding:1em;min-width:30px;position:relative}@media all and (max-width:450px){.darkmode{padding:1em}}.darkmode>.toggle{display:none;box-sizing:border-box}.darkmode svg{opacity:0;position:absolute;width:20px;height:20px;top:calc(50% - 10px);margin:0 7px;fill:var(--gray);transition:opacity .1s ease}.toggle:checked~label>#dayIcon{opacity:0}.toggle:checked~label>#nightIcon{opacity:1}.toggle:not(:checked)~label>#dayIcon{opacity:1}.toggle:not(:checked)~label>#nightIcon{opacity:0}
    </style>
    
    
    
    
    <style>
        .chroma{color:#f8f8f2;background-color:#282a36;overflow:hidden}.chroma .lntd{vertical-align:top;padding:0;margin:0;border:0}.chroma .lntable{border-spacing:0;padding:0;margin:0;border:0;width:auto;overflow:auto;display:block}.chroma .hl{display:block;width:100%;background-color:#ffc}.chroma .lnt{margin-right:.4em;padding:0 .4em;color:#7f7f7f}.chroma .ln{margin-right:.4em;padding:0 .4em;color:#7f7f7f}.chroma .k{color:#ff79c6}.chroma .kc{color:#ff79c6}.chroma .kd{color:#8be9fd;font-style:italic}.chroma .kn{color:#ff79c6}.chroma .kp{color:#ff79c6}.chroma .kr{color:#ff79c6}.chroma .kt{color:#8be9fd}.chroma .na{color:#50fa7b}.chroma .nb{color:#8be9fd;font-style:italic}.chroma .nc{color:#50fa7b}.chroma .nf{color:#50fa7b}.chroma .nl{color:#8be9fd;font-style:italic}.chroma .nt{color:#ff79c6}.chroma .nv{color:#8be9fd;font-style:italic}.chroma .vc{color:#8be9fd;font-style:italic}.chroma .vg{color:#8be9fd;font-style:italic}.chroma .vi{color:#8be9fd;font-style:italic}.chroma .s{color:#f1fa8c}.chroma .sa{color:#f1fa8c}.chroma .sb{color:#f1fa8c}.chroma .sc{color:#f1fa8c}.chroma .dl{color:#f1fa8c}.chroma .sd{color:#f1fa8c}.chroma .s2{color:#f1fa8c}.chroma .se{color:#f1fa8c}.chroma .sh{color:#f1fa8c}.chroma .si{color:#f1fa8c}.chroma .sx{color:#f1fa8c}.chroma .sr{color:#f1fa8c}.chroma .s1{color:#f1fa8c}.chroma .ss{color:#f1fa8c}.chroma .m{color:#bd93f9}.chroma .mb{color:#bd93f9}.chroma .mf{color:#bd93f9}.chroma .mh{color:#bd93f9}.chroma .mi{color:#bd93f9}.chroma .il{color:#bd93f9}.chroma .mo{color:#bd93f9}.chroma .o{color:#ff79c6}.chroma .ow{color:#ff79c6}.chroma .c{color:#6272a4}.chroma .ch{color:#6272a4}.chroma .cm{color:#6272a4}.chroma .c1{color:#6272a4}.chroma .cs{color:#6272a4}.chroma .cp{color:#ff79c6}.chroma .cpf{color:#ff79c6}.chroma .gd{color:#8b080b}.chroma .ge{text-decoration:underline}.chroma .gh{font-weight:700}.chroma .gi{font-weight:700}.chroma .go{color:#44475a}.chroma .gu{font-weight:700}.chroma .gl{text-decoration:underline}.lntd:first-of-type>.chroma{padding-right:0}.chroma code{font-family:jetbrains mono!important;font-size:.85em;line-height:1em;background:0 0;padding:0}.chroma{border-radius:3px;margin:0}
    </style>
    
    

    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.css" integrity="sha384-R4558gYOUz8mP9YWpZJjofhk+zx0AS11p36HnD2ZKj/6JR5z27gSSULCNHIRReVs" crossorigin="anonymous">
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.js" integrity="sha384-z1fJDqw8ZApjGO3/unPWUPsIymfsJmyrDVWC8Tv/a1HeOtGmkwNd/7xUS0Xcnvsx" crossorigin="anonymous"></script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/contrib/auto-render.min.js" integrity="sha384-+XBljXPPiv+OzfbB3cVmLHf4hdUFHlWNZN5spNQ7rmHTXpd7WvJum6fIACpNNfIR" crossorigin="anonymous"
        onload="renderMathInElement(document.body);"></script>
<script>
  document.addEventListener("DOMContentLoaded", function() {
    renderMathInElement(document.body, {
      
      
      delimiters: [
        {left: '$$', right: '$$', display: true},
        {left: '$', right: '$', display: false},
        {left: '\\(', right: '\\)', display: false},
        {left: '\\[', right: '\\]', display: true}
      ],
      
      throwOnError : false
    });
  });
</script><script>
      const userPref=window.matchMedia('(prefers-color-scheme: light)').matches?'light':'dark',currentTheme=localStorage.getItem('theme')??userPref,isReducedMotion=window.matchMedia('(prefers-reduced-motion: reduce)').matches,lastVisit=localStorage.getItem('lastVisitTime'),now=Date.now();let show='true';if(lastVisit){document.documentElement.setAttribute('visited','true');const a=Math.ceil((now-parseInt(lastVisit))/(1e3*60));show=!isReducedMotion&&a>5?'true':'false'}document.documentElement.setAttribute('show-animation',show),localStorage.setItem('lastVisitTime',`${now}`),currentTheme&&document.documentElement.setAttribute('saved-theme',currentTheme);const switchTheme=a=>{a.target.checked?(document.documentElement.setAttribute('saved-theme','dark'),localStorage.setItem('theme','dark')):(document.documentElement.setAttribute('saved-theme','light'),localStorage.setItem('theme','light'))};window.addEventListener('DOMContentLoaded',()=>{const a=document.querySelector('#darkmode-toggle');a.addEventListener('change',switchTheme,!1),currentTheme==='dark'&&(a.checked=!0)})
    </script>
    <script>
      let saved = false
      const fetchData = async () => {
        if (saved) {
          return saved
        } else {
          const promises = [
            fetch("/linkIndex.json")
              .then(data => data.json())
              .then(data => ({
                index: data.index,
                links: data.links,
              })),
            fetch("/contentIndex.json")
              .then(data => data.json()),
          ]
          const [{index, links}, content] = await Promise.all(promises)
          const res = ({
            index,
            links,
            content,
          })
          saved = res
          return res
        }

      }
      fetchData()
    </script>
</head>

<script type="application/javascript">
var doNotTrack = false;
if (!doNotTrack) {
	(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
	(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
	m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
	})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
	ga('create', 'UA-148413215-1', 'auto');
	
	ga('send', 'pageview');
}
</script>

<script>
  function htmlToElement(html) {
    const template = document.createElement('template')
    html = html.trim()
    template.innerHTML = html
    return template.content.firstChild
  }
  document.addEventListener("DOMContentLoaded", () => {
    fetchData().then(({content}) => {
      [...document.getElementsByClassName("internal-link")]
        .forEach(li => {
          const linkDest = content[li.dataset.src]
          if (linkDest) {
            const popoverElement = `<div class="popover">
    <h3>${linkDest.title}</h3>
    <p>${removeMarkdown(linkDest.content).split(" ", 20).join(" ")}...</p>
    <p class="meta">Updated ${new Date(linkDest.lastmodified).toLocaleDateString()}</p>
</div>`
            const el = htmlToElement(popoverElement)
            li.appendChild(el)
            li.addEventListener("mouseover", () => {
              el.classList.add("visible")
            })
            li.addEventListener("mouseout", () => {
              el.classList.remove("visible")
            })
          }
        })
    })

  })
</script>




<body>
<div id="search-container">
    <div id="search-space">
        <input autocomplete="off" id="search-bar" name="search" type="text" aria-label="Search" placeholder="Search for something...">
        <div id="results-container">
        </div>
    </div>
</div>
<script src="https://cdn.jsdelivr.net/gh/nextapps-de/flexsearch@0.7.2/dist/flexsearch.bundle.js"></script>
<script>
    
    const removeMarkdown = (
        markdown,
        options = {
            listUnicodeChar: false,
            stripListLeaders: true,
            gfm: true,
            useImgAltText: false,
            preserveLinks: false,
        }
    ) => {
        let output = markdown || "";
        output = output.replace(/^(-\s*?|\*\s*?|_\s*?){3,}\s*$/gm, "");

        try {
            if (options.stripListLeaders) {
                if (options.listUnicodeChar)
                    output = output.replace(
                        /^([\s\t]*)([\*\-\+]|\d+\.)\s+/gm,
                        options.listUnicodeChar + " $1"
                    );
                else output = output.replace(/^([\s\t]*)([\*\-\+]|\d+\.)\s+/gm, "$1");
            }
            if (options.gfm) {
                output = output
                    .replace(/\n={2,}/g, "\n")
                    .replace(/~{3}.*\n/g, "")
                    .replace(/~~/g, "")
                    .replace(/`{3}.*\n/g, "");
            }
            if (options.preserveLinks) {
                output = output.replace(/\[(.*?)\][\[\(](.*?)[\]\)]/g, "$1 ($2)")
            }
            output = output
                .replace(/<[^>]*>/g, "")
                .replace(/^[=\-]{2,}\s*$/g, "")
                .replace(/\[\^.+?\](\: .*?$)?/g, "")
                .replace(/\s{0,2}\[.*?\]: .*?$/g, "")
                .replace(/\!\[(.*?)\][\[\(].*?[\]\)]/g, options.useImgAltText ? "$1" : "")
                .replace(/\[(.*?)\][\[\(].*?[\]\)]/g, "$1")
                .replace(/^\s{0,3}>\s?/g, "")
                .replace(/(^|\n)\s{0,3}>\s?/g, "\n\n")
                .replace(/^\s{1,2}\[(.*?)\]: (\S+)( ".*?")?\s*$/g, "")
                .replace(
                    /^(\n)?\s{0,}#{1,6}\s+| {0,}(\n)?\s{0,}#{0,} {0,}(\n)?\s{0,}$/gm,
                    "$1$2$3"
                )
                .replace(/([\*_]{1,3})(\S.*?\S{0,1})\1/g, "$2")
                .replace(/([\*_]{1,3})(\S.*?\S{0,1})\1/g, "$2")
                .replace(/(`{3,})(.*?)\1/gm, "$2")
                .replace(/`(.+?)`/g, "$1")
                .replace(/\n{2,}/g, "\n\n");
        } catch (e) {
            console.error(e);
            return markdown;
        }
        return output;
    };
</script>
<script>
  async function run() {
    const contentIndex = new FlexSearch.Document({
      cache: true,
      charset: "latin:extra",
      optimize: true,
      worker: true,
      document: {
        index: [{
          field: "content",
          tokenize: "strict",
          context: {
            resolution: 5,
            depth: 3,
            bidirectional: true
          },
          suggest: true,
        }, {
          field: "title",
          tokenize: "forward",
        }]
      }
    })

    const { content } = await fetchData()
    for (const [key, value] of Object.entries(content)) {
      contentIndex.add({
        id: key,
        title: value.title,
        content: removeMarkdown(value.content),
      })
    }

    const highlight = (content, term) => {
      const highlightWindow = 20
      const tokenizedTerm = term.split(/\s+/).filter(t => t !== "")
      const splitText = content.split(/\s+/).filter(t => t !== "")
      const includesCheck = (token) => tokenizedTerm.some(term => token.toLowerCase().startsWith(term.toLowerCase()))

      const occurrencesIndices = splitText
        .map(includesCheck)

      
      let bestSum = 0
      let bestIndex = 0
      for (let i = 0; i < Math.max(occurrencesIndices.length - highlightWindow, 0); i++) {
        const window = occurrencesIndices.slice(i, i + highlightWindow)
        const windowSum = window.reduce((total, cur) => total + cur, 0)
        if (windowSum >= bestSum) {
          bestSum = windowSum
          bestIndex = i
        }
      }

      const startIndex = Math.max(bestIndex - highlightWindow, 0)
      const endIndex = Math.min(startIndex + 2 * highlightWindow, splitText.length)
      const mappedText = splitText
        .slice(startIndex, endIndex)
        .map(token => {
          if (includesCheck(token)) {
            return `<span class="search-highlight">${token}</span>`
          }
          return token
        })
        .join(" ")
        .replaceAll('</span> <span class="search-highlight">', " ")
      return `${startIndex === 0 ? "" : "..."}${mappedText}${endIndex === splitText.length ? "" : "..."}`
    }

    const resultToHTML = ({url, title, content, term}) => {
      const text = removeMarkdown(content)
      const resultTitle = highlight(title, term)
      const resultText = highlight(text, term)
      return `<button class="result-card" id="${url}">
        <h3>${resultTitle}</h3>
        <p>${resultText}</p>
    </button>`
    }

    const redir = (id, term) => {
      window.location.href = "https:\/\/jzhao.xyz\/" + `${id}#:~:text=${encodeURIComponent(term)}`
    }

    const formatForDisplay = id => ({
      id,
      url: id,
      title: content[id].title,
      content: content[id].content
    })

    const source = document.getElementById('search-bar')
    const results = document.getElementById("results-container")
    let term
    source.addEventListener("keyup", (e) => {
      if (e.key === "Enter") {
        const anchor = document.getElementsByClassName("result-card")[0]
        redir(anchor.id, term)
      }
    })
    source.addEventListener('input', (e) => {
      term = e.target.value
      contentIndex.search(term, [
        {
          field: "content",
          limit: 10,
          suggest: true,
        },
        {
          field: "title",
          limit: 5,
        }
      ]).then(searchResults => {
        const getByField = field => {
          const results = searchResults.filter(x => x.field === field)
          if (results.length === 0) {
            return []
          } else {
            return [...results[0].result]
          }
        }
        const allIds = new Set([...getByField('title'), ...getByField('content')])
        const finalResults = [...allIds].map(formatForDisplay)

        // display
        if (finalResults.length === 0) {
          results.innerHTML = `<button class="result-card">
                    <h3>No results.</h3>
                    <p>Try another search term?</p>
                </button>`
        } else {
          results.innerHTML = finalResults
            .map(result => resultToHTML({
              ...result,
              term,
            }))
            .join("\n")
          const anchors = document.getElementsByClassName("result-card");
          [...anchors].forEach(anchor => {
            anchor.onclick = () => redir(anchor.id, term)
          })
        }
      })
    })


    const searchContainer = document.getElementById("search-container")

    function openSearch() {
      if (searchContainer.style.display === "none" || searchContainer.style.display === "") {
        source.value = ""
        results.innerHTML = ""
        searchContainer.style.display = "block"
        source.focus()
      } else {
        searchContainer.style.display = "none"
      }
    }

    function closeSearch() {
      searchContainer.style.display = "none"
    }

    document.addEventListener('keydown', (event) => {
      if (event.key === "/") {
        event.preventDefault()
        openSearch()
      }
      if (event.key === "Escape") {
        event.preventDefault()
        closeSearch()
      }
    })

    window.addEventListener('DOMContentLoaded', () => {
      const searchButton = document.getElementById("search-icon")
      searchButton.addEventListener('click', (evt) => {
        openSearch()
      })
      searchButton.addEventListener('keydown', (evt) => {
        openSearch()
      })
      searchContainer.addEventListener('click', (evt) => {
        closeSearch()
      })
      document.getElementById("search-space").addEventListener('click', (evt) => {
        evt.stopPropagation()
      })
    })
  }

  run()
</script>

<div class="singlePage">
    
    <header>
        <h1 id="page-title"><a href="https://jzhao.xyz/">jzhao.xyz</a></h1>
      <svg tabindex="0" id="search-icon" aria-labelledby="title desc" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 19.9 19.7"><title id="title">Search Icon</title><desc id="desc">Icon to open search</desc><g class="search-path" fill="none"><path stroke-linecap="square" d="M18.5 18.3l-5.4-5.4"/><circle cx="8" cy="8" r="7"/></g></svg>
      <div class="spacer"></div>
      <div class='darkmode'>
    <input class='toggle' id='darkmode-toggle' type='checkbox' tabindex="-1">
    <label id="toggle-label-light" for='darkmode-toggle' tabindex="-1">
        <svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" version="1.1" id="dayIcon" x="0px" y="0px" viewBox="0 0 35 35" style="enable-background:new 0 0 35 35;" xml:space="preserve">
            <title>Light Mode</title>
            <path d="M6,17.5C6,16.672,5.328,16,4.5,16h-3C0.672,16,0,16.672,0,17.5    S0.672,19,1.5,19h3C5.328,19,6,18.328,6,17.5z M7.5,26c-0.414,0-0.789,0.168-1.061,0.439l-2,2C4.168,28.711,4,29.086,4,29.5    C4,30.328,4.671,31,5.5,31c0.414,0,0.789-0.168,1.06-0.44l2-2C8.832,28.289,9,27.914,9,27.5C9,26.672,8.329,26,7.5,26z M17.5,6    C18.329,6,19,5.328,19,4.5v-3C19,0.672,18.329,0,17.5,0S16,0.672,16,1.5v3C16,5.328,16.671,6,17.5,6z M27.5,9    c0.414,0,0.789-0.168,1.06-0.439l2-2C30.832,6.289,31,5.914,31,5.5C31,4.672,30.329,4,29.5,4c-0.414,0-0.789,0.168-1.061,0.44    l-2,2C26.168,6.711,26,7.086,26,7.5C26,8.328,26.671,9,27.5,9z M6.439,8.561C6.711,8.832,7.086,9,7.5,9C8.328,9,9,8.328,9,7.5    c0-0.414-0.168-0.789-0.439-1.061l-2-2C6.289,4.168,5.914,4,5.5,4C4.672,4,4,4.672,4,5.5c0,0.414,0.168,0.789,0.439,1.06    L6.439,8.561z M33.5,16h-3c-0.828,0-1.5,0.672-1.5,1.5s0.672,1.5,1.5,1.5h3c0.828,0,1.5-0.672,1.5-1.5S34.328,16,33.5,16z     M28.561,26.439C28.289,26.168,27.914,26,27.5,26c-0.828,0-1.5,0.672-1.5,1.5c0,0.414,0.168,0.789,0.439,1.06l2,2    C28.711,30.832,29.086,31,29.5,31c0.828,0,1.5-0.672,1.5-1.5c0-0.414-0.168-0.789-0.439-1.061L28.561,26.439z M17.5,29    c-0.829,0-1.5,0.672-1.5,1.5v3c0,0.828,0.671,1.5,1.5,1.5s1.5-0.672,1.5-1.5v-3C19,29.672,18.329,29,17.5,29z M17.5,7    C11.71,7,7,11.71,7,17.5S11.71,28,17.5,28S28,23.29,28,17.5S23.29,7,17.5,7z M17.5,25c-4.136,0-7.5-3.364-7.5-7.5    c0-4.136,3.364-7.5,7.5-7.5c4.136,0,7.5,3.364,7.5,7.5C25,21.636,21.636,25,17.5,25z" />
        </svg>
    </label>
    <label id="toggle-label-dark" for='darkmode-toggle' tabindex="-1">
        <svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" version="1.1" id="nightIcon" x="0px" y="0px" viewBox="0 0 100 100" style="enable-background='new 0 0 100 100'" xml:space="preserve">
            <title>Dark Mode</title>
            <path d="M96.76,66.458c-0.853-0.852-2.15-1.064-3.23-0.534c-6.063,2.991-12.858,4.571-19.655,4.571  C62.022,70.495,50.88,65.88,42.5,57.5C29.043,44.043,25.658,23.536,34.076,6.47c0.532-1.08,0.318-2.379-0.534-3.23  c-0.851-0.852-2.15-1.064-3.23-0.534c-4.918,2.427-9.375,5.619-13.246,9.491c-9.447,9.447-14.65,22.008-14.65,35.369  c0,13.36,5.203,25.921,14.65,35.368s22.008,14.65,35.368,14.65c13.361,0,25.921-5.203,35.369-14.65  c3.872-3.871,7.064-8.328,9.491-13.246C97.826,68.608,97.611,67.309,96.76,66.458z" />
        </svg>
    </label>
</div>
  </header>
    
    <pre class="ascii ascii-dark">
     <span class="ascii-tertiary">.</span> _
<span class="ascii-tertiary">.</span>_   \/ <span class="ascii-primary">@</span>
<span class="ascii-primary">@</span> \<span class="ascii-tertiary">.</span>_/
  //
</pre>
    
    <h1 class="title">reflect: NLP Model Explained</h1>
    <article>
      <p class="meta">
          Last updated December 25, 2021
      </p>
      <ul class="tags">
    
    <li><a href="https://jzhao.xyz/tags/technical/">Technical</a></li>
    
    <li><a href="https://jzhao.xyz/tags/fruit/">Fruit</a></li>
    
</ul>
      
      <aside class="mainTOC">
          <h3>Table of Contents</h3>
          <nav id="TableOfContents">
  <ol>
    <li><a href="#the-problem">The problem</a></li>
    <li><a href="#why-its-so-difficult">Why it’s so difficult</a></li>
    <li><a href="#the-data">The data</a>
      <ol>
        <li><a href="#survey-data-444-entries">Survey data (444 entries)</a></li>
        <li><a href="#closed-beta-790-entries">Closed Beta (790 entries)</a></li>
        <li><a href="#closed-beta-corrections-37-entries">Closed Beta Corrections (37 entries)</a></li>
        <li><a href="#so">So?</a></li>
      </ol>
    </li>
    <li><a href="#data-augmentation">Data augmentation</a>
      <ol>
        <li><a href="#sentence-variation">Sentence Variation</a></li>
        <li><a href="#sentence-negation">Sentence Negation</a></li>
        <li><a href="#shuffled-sentences">Shuffled Sentences</a></li>
        <li><a href="#garbage-sentences">Garbage Sentences</a></li>
        <li><a href="#vocabulary-mix-sentences">Vocabulary-mix Sentences</a></li>
      </ol>
    </li>
    <li><a href="#data-preprocessing">Data preprocessing</a>
      <ol>
        <li><a href="#strip-punctuation">Strip punctuation</a></li>
        <li><a href="#make-everything-lowercase">Make everything lowercase</a></li>
        <li><a href="#expand-contractions">Expand contractions</a></li>
        <li><a href="#remove-stop-words">Remove stop words</a></li>
        <li><a href="#tokenization">Tokenization</a></li>
        <li><a href="#fixed-sequence-length">Fixed sequence length</a></li>
        <li><a href="#finally">Finally</a></li>
      </ol>
    </li>
    <li><a href="#whats-next">What’s next?</a></li>
    <li><a href="#the-model">The model</a>
      <ol>
        <li><a href="#model-overview">Model Overview</a></li>
      </ol>
    </li>
    <li><a href="#training-pipeline">Training pipeline</a></li>
    <li><a href="#serving-the-model">Serving the model</a></li>
    <li><a href="#future-improvement">Future improvement</a>
      <ol>
        <li><a href="#possible-models">Possible models</a></li>
        <li><a href="#misclassifications">Misclassifications</a></li>
      </ol>
    </li>
    <li><a href="#closing">Closing</a></li>
  </ol>
</nav>
      </aside>
      
      <p>
<img src="https://miro.medium.com/max/1400/1*yjCs2Mmcve8wNI1pdfXelw.png" alt="An image of the reflect block page"  /><em>How do we tell that this is a “valid” intent?</em></p>
<p>A (not so) brief exploration of how we tackle classifying intents in reflect. Part 1 will touch on defining the problem we’re trying to solve, the data we have, and how we pre-processed it. Part 2 will focus on the architecture of the model we built, how well it does, and thoughts on improving it for the future.</p>
<h2 id="the-problem">The problem</h2>
<p>Classifying intents is at the core of reflect. When a user inputs an intent, its reflect’s job to figure out whether that intent should let them into the website.</p>
<blockquote>
<p>How do we make sure “do some marketing work for reflect” is classified as productive but “watch cute dog videos” isn’t?</p>
</blockquote>
<h2 id="why-its-so-difficult">Why it’s so difficult</h2>
<p>A lot of it comes down to the fact that natural language processing (NLP) is a very difficult task. What does the sentence “learn about physics” mean, and how is it semantically different from “asdflkj I can’t do work”?</p>
<p>We can’t just parse for keywords and just allow a user in if we see the word “work” because that word can mean different things in different contexts. For example, “I’m not doing any work right now” would have otherwise been classified as valid. Thus, we can employ the help of a machine learning algorithm to help us capture this deeper meaning.</p>
<p>Specifically, the form of machine learning we will be using is called <strong>supervised learning,</strong> in which we give an algorithm a bunch of labelled data, tell it what it’s doing wrong, and let it ‘learn.’ Through doing this, hopefully the algorithm will be able to generalize and make predictions on unseen data too.</p>
<h2 id="the-data">The data</h2>
<p>Of course, if we want to perform supervised learning, we’re going to need a lot of data. Where are we going to get all of it? Luckily, we were able to get it through 3 different sources.</p>
<h3 id="survey-data-444-entries">Survey data (444 entries)</h3>
<p>Our team sent out an interest survey in early January in which we asked 3 questions:</p>
<ol>
<li>
<p>How would you answer if you were trying to visit a distracting site while trying to focus? (eg. youtube, facebook, etc)</p>
</li>
<li>
<p>How would you answer if you were trying to visit a distracting site to take a quick break from your work? (eg. youtube, facebook, etc)</p>
</li>
<li>
<p>How would you answer if you were trying to visit a distracting site like Facebook but to do work? (e.g. make a marketing post)</p>
</li>
</ol>
<p>We used these answers to form the basis of our very first dataset. We ended up getting a surprising amount of entries, ending with 148 responses to 3 questions and totalling 444 different observations. Here’s what some of that data looks like after tidying it up:</p>
<blockquote>
<p>We classified any answer to Q1 as invalid and Q2 + Q3 as valid</p>
</blockquote>
<table>
<thead>
<tr>
<th>intent</th>
<th>valid</th>
</tr>
</thead>
<tbody>
<tr>
<td>I am watching a 5 minute video to take my mind off not being productive :/</td>
<td>no</td>
</tr>
<tr>
<td>I&rsquo;m just bored</td>
<td>no</td>
</tr>
<tr>
<td>I’m bored/tired and trying to relax</td>
<td>no</td>
</tr>
<tr>
<td>&hellip;</td>
<td>&hellip;</td>
</tr>
<tr>
<td>work is pretty boring, i need to take a quick break I just can&rsquo;t focus atm</td>
<td>yes</td>
</tr>
<tr>
<td>I finished all my work for today so I&rsquo;m going to take a break now!</td>
<td>yes</td>
</tr>
<tr>
<td>getting some advertising done for my club</td>
<td>yes</td>
</tr>
<tr>
<td>I need to make a post on Twitter for my job announcing the latest update to our site</td>
<td>yes</td>
</tr>
<tr>
<td>I&rsquo;m trying to network</td>
<td>yes</td>
</tr>
<tr>
<td>&hellip;</td>
<td>&hellip;</td>
</tr>
</tbody>
</table>
<h3 id="closed-beta-790-entries">Closed Beta (790 entries)</h3>
<p>After we made a basic dataset, we were able to make our first (admittedly not great) model. But in doing so, this let us create an MVP to which we could use to actually test with. We then deployed this model for use to our closed beta testers and collected their responses (with consent of course!) along with the website it was input on. This was then converted into a .csv file. A few examples are show below:</p>
<table>
<thead>
<tr>
<th>intent</th>
<th>url</th>
</tr>
</thead>
<tbody>
<tr>
<td>to do some marketing</td>
<td>facebook.com/</td>
</tr>
<tr>
<td>i cannot focus on my work</td>
<td>instagram.com/</td>
</tr>
<tr>
<td>fuel my crippling social media addiction</td>
<td>facebook.com/</td>
</tr>
<tr>
<td>&hellip;</td>
<td>&hellip;</td>
</tr>
</tbody>
</table>
<p>These were then hand-labelled by our reflect team in a similar format as the survey data we collected earlier.</p>
<table>
<thead>
<tr>
<th>intent</th>
<th>valid</th>
</tr>
</thead>
<tbody>
<tr>
<td>to do some marketing</td>
<td>yes</td>
</tr>
<tr>
<td>i cannot focus on my work</td>
<td>no</td>
</tr>
<tr>
<td>fuel my crippling social media addiction</td>
<td>no</td>
</tr>
<tr>
<td>&hellip;</td>
<td>&hellip;</td>
</tr>
</tbody>
</table>
<h3 id="closed-beta-corrections-37-entries">Closed Beta Corrections (37 entries)</h3>
<p>Finally, we created a Google Forms through which we directly asked beta testers if a decision made by reflect’s intent classifier was faulty. Specifically, we asked what they input, and what they expected. Here are a few examples:</p>
<table>
<thead>
<tr>
<th>input</th>
<th>valid</th>
</tr>
</thead>
<tbody>
<tr>
<td>reply to a friend about a lab</td>
<td>yes</td>
</tr>
<tr>
<td>listening to a youtube music playlist</td>
<td>yes</td>
</tr>
<tr>
<td>goof off as much as possible</td>
<td>yes</td>
</tr>
<tr>
<td>&hellip;</td>
<td>&hellip;</td>
</tr>
</tbody>
</table>
<p>This entire section of the dataset was only 37 observations, but it drastically helped us reduce false positives and false negatives by focusing specifically on misclassifications.</p>
<p>After aggregating and combing all our data into one common format, we ended up with a grand total of 1271 observations. They looked something like this:</p>
<table>
<thead>
<tr>
<th>input</th>
<th>expected</th>
</tr>
</thead>
<tbody>
<tr>
<td>fail school by watching youtube</td>
<td>no</td>
</tr>
<tr>
<td>sdlkjasd</td>
<td>no</td>
</tr>
<tr>
<td>making a quick product post (should take &lt;10 min)</td>
<td>yes</td>
</tr>
<tr>
<td>&hellip;</td>
<td>&hellip;</td>
</tr>
</tbody>
</table>
<h3 id="so">So?</h3>
<p>Now that we have the data, can we just throw it into a machine learning model? Unfortunately, the answer is no, not quite yet.</p>
<h2 id="data-augmentation">Data augmentation</h2>
<p>Our dataset is still pretty small, even after aggregating all of our data. It most definitely doesn’t cover all of our bases for all the possible things that future users could possibly input. So, how can we “upsample” our data to get more of it? Well, it turns out that the field of Natural Language Processing has quite a few tricks to augment our data.</p>
<h3 id="sentence-variation">Sentence Variation</h3>
<p>Essentially what sentence variation is, is just replacing a few words of given sentences with their synonyms. If we have a sentence like “I’m trying to make a marketing post,” we can swap out singular words with their synonyms and tell our network that it means the same thing.</p>
<p>In this example, we could get something like “I’m attempting to fabricate a marketing post”. Adding these additional sentence variations will allow our machine learning model to learn semantic relationships between similar words (e.g. fabricate and make have similar meaning)</p>
<h3 id="sentence-negation">Sentence Negation</h3>
<p>Additionally, if we add a ‘not’ in the sentence, it should flip the meaning of the sentence. An example would be “learning about physics” is valid, whereas “not learning about physics” is not. However, if the sentence already contains ‘not’ (e.g. “I’m not being productive”), adding another ‘not’ would make the sentence too complex and obfuscated, so we just label it as invalid. In essence, we just add ‘not’ to a bunch of sentences and label them as invalid. This helps us to combat intents which use negations in a sort of round-a-bout way to confuse the algorithm.</p>
<h3 id="shuffled-sentences">Shuffled Sentences</h3>
<p>If we take an existing, valid sentence and completely shuffle the words, the resulting sentence should be invalid. An example would be “to watch a crash course video*” should be valid whereas “video course a watch crash to*” should be invalid. Basically, we’re just shuffling existing sentences and also labelling them as invalid. This helps us to combat intents which grammatically make no sense, but are otherwise valid.</p>
<h3 id="garbage-sentences">Garbage Sentences</h3>
<p>We can also take completely random words from the English language and put them together. The resulting sentences should all be invalid. For example, “*untinkered phalangitis shaly quinovic dish spadiciflorous unshaved” *clearly makes no sense. However, the addition of these gibberish sentences allows our model to be more robust against foreign words and out-of-vocabulary terms.</p>
<h3 id="vocabulary-mix-sentences">Vocabulary-mix Sentences</h3>
<p>Last but definitely not least, we can take the most common words in our dataset and mash them together. This should yield us a bunch of sentences which contain “key words” but should be marked as invalid because the context in which they are used makes no sense. For example, “video look watching” and “get research facebook take need want need message watch” are both clearly gibberish sentences, but they have a lot of keywords that one would think would let you in (e.g. video, research, watching, etc.). This lets us be more robust against those who try to get around the algorithm using keywords.</p>
<h2 id="data-preprocessing">Data preprocessing</h2>
<p>What about now? Can we throw it into the neural network yet? Well, no. We may have increased the amount of data we have to work with, but we also need to convert it to a form that is easy to understand for both the computer and for our algorithm. We do that with a series of functions that we apply on our data.</p>
<h3 id="strip-punctuation">Strip punctuation</h3>
<p>As the name suggests, we remove all punctuation from the input phrase. We found that including the punctuation hurt our performance, most likely due to the fact that they offer very little in terms of semantic meaning and obfuscate the real meaning of the sentence.</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">stripPunctuation</span><span class="p">(</span><span class="s2">&#34;I don&#39;t know if I&#39;m being productive! :(&#34;</span><span class="p">)</span> 
<span class="o">&gt;</span> <span class="s2">&#34;I dont know if Im being productive&#34;</span>
</code></pre></td></tr></table>
</div>
</div><h3 id="make-everything-lowercase">Make everything lowercase</h3>
<p>Additionally, we found that in this particular setting, capital letters also didn’t matter that much. Because of the nature we collect our data (just a simple textbox), users tend to not bother with capitalization. As such, we remove it to make it consistent across our data.</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">lower</span><span class="p">(</span><span class="s2">&#34;I dont know if Im being productive&#34;</span><span class="p">)</span>
<span class="o">&gt;</span> <span class="s2">&#34;i dont know if im being productive&#34;</span>
</code></pre></td></tr></table>
</div>
</div><h3 id="expand-contractions">Expand contractions</h3>
<p>The English language does this weird thing where we can just smush two words together (e.g. “I am” to “I’m”). Unfortunately for us, these produce extra complexity in our model that we could reduce by making them all consistent. In our case, we chose to expand all of these contractions.</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">expandContractions</span><span class="p">(</span><span class="s2">&#34;i dont know if im being productive&#34;</span><span class="p">)</span> 
<span class="o">&gt;</span> <span class="s2">&#34;i do not know if i am being productive&#34;</span>
</code></pre></td></tr></table>
</div>
</div><h3 id="remove-stop-words">Remove stop words</h3>
<p>The English language also has a bunch of these things called <strong>stop words</strong> — words that do not contribute anything major to the sentence in terms of semantic understanding (usually in the context of natural language tasks such as this). A few examples of them are ‘I’, ‘me’, ‘my’, ‘by’, and ‘on’. By removing them, we once again remove unneeded complexity from the model.</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">rmStopwords</span><span class="p">(</span><span class="s2">&#34;i do not know if i am being productive&#34;</span><span class="p">)</span> 
<span class="o">&gt;</span> <span class="s2">&#34;not know productive&#34;</span>
</code></pre></td></tr></table>
</div>
</div><h3 id="tokenization">Tokenization</h3>
<p>However, these words are not super friendly for machine learning algorithms who would much rather deal with integers and floating point numbers than words and sentences. How do we fix this?</p>
<p>Well, one thing we can do is turn words in indices by how often they appear, capped at the most common 1000 words — in essence, creating a vocabulary list mapping common words to numbers. For example, if “the” is the most common word, we convert it to 1. If “work” is the 8th most common word, we convert it to 8. For anything that isn’t in the top 1000, we give it the value of 0.</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">tokenize</span><span class="p">(</span><span class="s2">&#34;not know productive&#34;</span><span class="p">)</span> 
<span class="o">&gt;</span> <span class="p">[</span><span class="mi">12</span><span class="p">,</span> <span class="mi">35</span><span class="p">,</span> <span class="mi">7</span><span class="p">]</span>
</code></pre></td></tr></table>
</div>
</div><h3 id="fixed-sequence-length">Fixed sequence length</h3>
<p>Finally, we need to ensure that all the inputs are the same length of simplicity sake. If we were to handle dynamic length inputs, it would introduce a whole other level of complexity that we’re really not ready to deal with. As such, we can make sure all the inputs are the same length by adding a bunch of zeros to those who are too short (zero padding) or by slicing those who are too long.</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">pad</span><span class="p">([</span><span class="mi">12</span><span class="p">,</span> <span class="mi">35</span><span class="p">,</span> <span class="mi">7</span><span class="p">],</span> <span class="mi">10</span><span class="p">)</span> 
<span class="o">&gt;</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">12</span><span class="p">,</span> <span class="mi">35</span><span class="p">,</span> <span class="mi">7</span><span class="p">]</span>
</code></pre></td></tr></table>
</div>
</div><h3 id="finally">Finally</h3>
<p>After all of these functions have been applied, we have successfully converted a complex sentence into a series of ‘tokens’ that is easy to understand for the machine learning algorithm.</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">preprocess</span><span class="p">(</span><span class="s2">&#34;I don’t know if I’m being productive! :(&#34;</span><span class="p">)</span>
<span class="o">&gt;</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">12</span><span class="p">,</span> <span class="mi">35</span><span class="p">,</span> <span class="mi">7</span><span class="p">]</span>
</code></pre></td></tr></table>
</div>
</div><h2 id="whats-next">What’s next?</h2>
<p>Now that we have something ready to feed into our neural network, let’s dive into how the actual model itself works! How do we tell that this is a “valid” intent?</p>
<h2 id="the-model">The model</h2>
<p>The type of neural network that we’ll be using is called Long Short-Term Memory (LSTM).</p>
<p>
<img src="https://cdn-images-1.medium.com/max/4000/0*HyoZq6fOfsnn2YOC" alt="credit: Christopher Olah, 2015"  /><em>credit: Christopher Olah, 2015</em></p>
<p>What’s so special about these networks is that they are really good at modelling time-series data, making it an ideal candidate for tasks like forecasting or natural language processing.</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="c1"># Function to create a RNN model with given parameters</span>
<span class="c1"># max_seq_len: maximum token sequence length</span>
<span class="c1"># vocab_size:  size of tokenizer vocabulary</span>
<span class="k">def</span> <span class="nf">RNN</span><span class="p">(</span><span class="n">max_seq_len</span><span class="p">,</span> <span class="n">vocab_size</span><span class="p">):</span>
    <span class="n">inputs</span> <span class="o">=</span> <span class="n">Input</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s1">&#39;inputs&#39;</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="n">max_seq_len</span><span class="p">])</span>
    <span class="n">layer</span> <span class="o">=</span> <span class="n">Embedding</span><span class="p">(</span><span class="n">vocab_size</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="n">input_length</span><span class="o">=</span><span class="n">max_seq_len</span><span class="p">)(</span><span class="n">inputs</span><span class="p">)</span>
    <span class="n">layer</span> <span class="o">=</span> <span class="n">LSTM</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="n">return_sequences</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)(</span><span class="n">layer</span><span class="p">)</span>
    <span class="n">layer</span> <span class="o">=</span> <span class="n">Dropout</span><span class="p">(</span><span class="mf">0.5</span><span class="p">)(</span><span class="n">layer</span><span class="p">)</span>
    <span class="n">layer</span> <span class="o">=</span> <span class="n">LSTM</span><span class="p">(</span><span class="mi">64</span><span class="p">)(</span><span class="n">layer</span><span class="p">)</span>
    <span class="n">layer</span> <span class="o">=</span> <span class="n">Dense</span><span class="p">(</span><span class="mi">256</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;FC1&#39;</span><span class="p">)(</span><span class="n">layer</span><span class="p">)</span>
    <span class="n">layer</span> <span class="o">=</span> <span class="n">Dropout</span><span class="p">(</span><span class="mf">0.5</span><span class="p">)(</span><span class="n">layer</span><span class="p">)</span>
    <span class="n">layer</span> <span class="o">=</span> <span class="n">Dense</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;out_layer&#39;</span><span class="p">)(</span><span class="n">layer</span><span class="p">)</span>
    <span class="n">layer</span> <span class="o">=</span> <span class="n">Activation</span><span class="p">(</span><span class="s1">&#39;sigmoid&#39;</span><span class="p">)(</span><span class="n">layer</span><span class="p">)</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">Model</span><span class="p">(</span><span class="n">inputs</span><span class="o">=</span><span class="n">inputs</span><span class="p">,</span> <span class="n">outputs</span><span class="o">=</span><span class="n">layer</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">model</span>
</code></pre></td></tr></table>
</div>
</div><p>Here’s how we define it in our 

<a href="https://github.com/jackyzha0/reflect-nlp/blob/master/nlp/net.py" rel="noopener">Keras code</a>, don’t worry if you don’t understand it just yet! We’ll explain it in the next few paragraphs.</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">inputs</span> <span class="o">=</span> <span class="n">Input</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s1">&#39;inputs&#39;</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="n">max_seq_len</span><span class="p">])</span>
</code></pre></td></tr></table>
</div>
</div><p>Right off the bat, you’ll notice that the first layer is the Input layer. Basically, this tells Keras to instantiate a new tensor (a multi-dimensional vector) with a given shape. In this case, we’re creating a one-dimensional tensor that is max_seq_len units long. When we trained our model, this was set to 75.</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">layer</span> <span class="o">=</span> <span class="n">Embedding</span><span class="p">(</span><span class="n">vocab_size</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="n">input_length</span><span class="o">=</span><span class="n">max_seq_len</span><span class="p">)(</span><span class="n">inputs</span><span class="p">)</span>
</code></pre></td></tr></table>
</div>
</div><p>Next up, we have the Embedding layer. We could get into a really technical discussion about what this really does, but you can think of it as a layer that helps the neural network to learn semantic relationships between inputs.</p>
<p>
<img src="https://cdn-images-1.medium.com/max/3010/0*YOZ_CfmtgpUbJ9BD" alt="credit: Rutger Ruizendaal, 2017"  /><em>credit: Rutger Ruizendaal, 2017</em></p>
<p>Essentially, it embeds tokens in a higher dimension vector space, where distance between tokens represents its similarity.</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">layer</span> <span class="o">=</span> <span class="n">LSTM</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="n">return_sequences</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)(</span><span class="n">layer</span><span class="p">)</span>
</code></pre></td></tr></table>
</div>
</div><p>Now, we get into the meat of the neural network: the LSTM layer. As stated before, these LSTM networks are really good at modelling time series data like language. In this case, our LSTM network has 64 hidden units per cell, and that we’d like to pass these hidden states to the next layer. If you’d like to learn more about the inner workings of the LSTM model, theres a really good resource 

<a href="https://towardsdatascience.com/illustrated-guide-to-lstms-and-gru-s-a-step-by-step-explanation-44e9eb85bf21" rel="noopener">here</a>!</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">layer</span> <span class="o">=</span> <span class="n">Dropout</span><span class="p">(</span><span class="mf">0.5</span><span class="p">)(</span><span class="n">layer</span><span class="p">)</span>
</code></pre></td></tr></table>
</div>
</div><p>Next, you’ll notice there are a few Dropout layers. These layers help to prevent overfitting by randomly killing off connections between the two layers (a sort of regularization). This makes sure neurons aren’t just “memorizing” the input data. This is especially important because our dataset is relatively small (~2000 observations even after augmentation), so making sure that our machine learning model can generalize outside of this limited dataset is really important.</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">layer</span> <span class="o">=</span> <span class="n">LSTM</span><span class="p">(</span><span class="mi">64</span><span class="p">)(</span><span class="n">layer</span><span class="p">)</span>
</code></pre></td></tr></table>
</div>
</div><p>We have yet another LSTM layer! By having these two chained right after each other, the first layer can pass all the values of all of its hidden states to the second layer, effectively allowing a sort of ‘deeper’ neural network.</p>
<p>
<img src="https://cdn-images-1.medium.com/max/2000/0*0BRdnA5sJBYbaeR9" alt="credit: Jianjing Zhang 2018"  /><em>credit: Jianjing Zhang 2018</em></p>
<p>This deep LSTM allows our network to learn more abstract concepts, making them well suited for natural language tasks.</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">layer</span> <span class="o">=</span> <span class="n">Dense</span><span class="p">(</span><span class="mi">256</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;FC1&#39;</span><span class="p">)(</span><span class="n">layer</span><span class="p">)</span>
</code></pre></td></tr></table>
</div>
</div><p>Next, we have something called a Fully Connected layer, or a Dense layer. In a dense layer, each of the input neurons is connected to every output neuron. This kind of ‘glue’ layer helps the network to pick out and discriminate feature output by our previous LSTM layer.</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">layer</span> <span class="o">=</span> <span class="n">Dense</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;out_layer&#39;</span><span class="p">)(</span><span class="n">layer</span><span class="p">)</span>
<span class="n">layer</span> <span class="o">=</span> <span class="n">Activation</span><span class="p">(</span><span class="s1">&#39;sigmoid&#39;</span><span class="p">)(</span><span class="n">layer</span><span class="p">)</span>
</code></pre></td></tr></table>
</div>
</div><p>Similarly, we have one final Dense layer that ‘compresses’ all of the hidden units down to one neuron. However, we want the output value of this neuron to be how confident from a scale of 0 to 1 it is that the intent is valid. We do this by applying something called an activation function.</p>
<p>
<img src="https://cdn-images-1.medium.com/max/2000/0*kdowh3GOGOUvGBr0" alt="A sigmoid activation function"  /></p>
<p>In this case, the particular function we chose is the sigmoid activation function, which looks something like the above.</p>
<h3 id="model-overview">Model Overview</h3>
<p>Phew, finally got through everything! After putting it all together, we end up with a network that looks something like this:</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span><span class="lnt">27
</span><span class="lnt">28
</span><span class="lnt">29
</span><span class="lnt">30
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="c1"># 75 max_seq_len</span>
<span class="c1"># 1000 tokenizer_vocab_size</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">net</span><span class="o">.</span><span class="n">RNN</span><span class="p">(</span><span class="mi">75</span><span class="p">,</span> <span class="mi">1000</span><span class="p">)</span> 
<span class="n">model</span><span class="o">.</span><span class="n">summary</span><span class="p">()</span>

<span class="c1"># _________________________________________________________________</span>
<span class="c1"># Layer (type)                 Output Shape              Param #   </span>
<span class="c1"># =================================================================</span>
<span class="c1"># inputs (InputLayer)          (None, 75)                0         </span>
<span class="c1"># _________________________________________________________________</span>
<span class="c1"># embedding_1 (Embedding)      (None, 75, 64)            64000     </span>
<span class="c1"># _________________________________________________________________</span>
<span class="c1"># lstm_1 (LSTM)                (None, 75, 64)            33024     </span>
<span class="c1"># _________________________________________________________________</span>
<span class="c1"># dropout_1 (Dropout)          (None, 75, 64)            0         </span>
<span class="c1"># _________________________________________________________________</span>
<span class="c1"># lstm_2 (LSTM)                (None, 64)                33024     </span>
<span class="c1"># _________________________________________________________________</span>
<span class="c1"># FC1 (Dense)                  (None, 256)               16640     </span>
<span class="c1"># _________________________________________________________________</span>
<span class="c1"># dropout_2 (Dropout)          (None, 256)               0         </span>
<span class="c1"># _________________________________________________________________</span>
<span class="c1"># out_layer (Dense)            (None, 1)                 257       </span>
<span class="c1"># _________________________________________________________________</span>
<span class="c1"># activation_1 (Activation)    (None, 1)                 0         </span>
<span class="c1"># =================================================================</span>
<span class="c1"># Total params: 146,945</span>
<span class="c1"># Trainable params: 146,945</span>
<span class="c1"># Non-trainable params: 0</span>
<span class="c1"># _________________________________________________________________</span>
</code></pre></td></tr></table>
</div>
</div><p>Theres a grand total of 150,000 different trainable knobs and parameters in our neural network!</p>
<h2 id="training-pipeline">Training pipeline</h2>
<p>So, how does the data we got earlier play a role in helping our machine learning model learn and improve?</p>
<p>The first component is the <strong>loss function.</strong> This component tells the neural network how ‘correct’ its prediction was. In this model, we will use something called 

<a href="https://towardsdatascience.com/understanding-binary-cross-entropy-log-loss-a-visual-explanation-a3ac6025181a" rel="noopener">binary cross entropy</a>, which is basically a fancy word for log-based error. If the true label is 1, we can then show what the log-loss would be for some given prediction probability.</p>
<p>
<img src="https://cdn-images-1.medium.com/max/2000/0*8rd4ho_3Y6zrtra-.png" alt=""  /></p>
<p>Next, we need to pick an <strong>optimizer</strong>. This component tells the neural network how to change its parameters to improve or ‘optimize’ itself. In this model, we chose to use an optimizer called 

<a href="https://towardsdatascience.com/understanding-rmsprop-faster-neural-network-learning-62e116fcf29a" rel="noopener">RMSProp</a> with a learning rate of 1e-3 . We aren’t going to cover all the technical details of this optimizer in this blog post, but just know that it is a very fast and effective optimizer.</p>
<p>
<img src="https://cdn-images-1.medium.com/max/2000/0*HZM5XJ-quu276w39.gif" alt="RMSProp(black) vs a bunch of other optimizers. credit: Vitaly Bushaev"  /><em>RMSProp(black) vs a bunch of other optimizers. credit: Vitaly Bushaev</em></p>
<p>One important hyperparameter we choose is the <strong>train-test split.</strong> In data science and machine learning, we typically withhold part of our data and set it aside as a <strong>test set</strong>. The rest of the data will be considered the <strong>training set.</strong> When training the model, we never feed it the test set. As a result, we can use the test set as a metric to see how well it would perform on real-world, unseen data. In our training, we used a train-test split of 20%.</p>
<p>Another important hyperparameter that we can choose is the <strong>mini-batch size</strong>. The mini-batch size determines how many training examples we feed the machine learning model before updating its parameters. A smaller mini-batch means that we get more frequent updates to the parameters, but it also runs the risk of having outliers that may cause a bad gradient update. A large mini-batch means that we get a more accurate gradient update but it also takes longer. A similar concept is <em>sample size</em> in statistics. We could pick a larger sample to get a better estimate of the overall population, but it is often more expensive to do so. A smaller sample might contain outliers and thus be less robust of an estimate of the overall population, but it very easy to do. So, there’s this tradeoff between accuracy and speed. We found that a good balance between these was a mini-batch size of 128.</p>
<p>We then trained our neural network over 10 epochs. A single epoch is one iteration over the entire dataset. If we train it for too many epochs, you run the risk of overfitting (memorizing the training data), but we don’t train it enough, we run the risk of not discovering a better model. One thing we can do it minimize this problem is through the use of cross-validation, which is a technique that lets us ‘test’ on portions of the training set. Essentially, at each iteration during training, we withhold a portion of the training set and use it as a sort of ‘validation’.</p>
<p>
<img src="https://cdn-images-1.medium.com/max/2000/0*6XoMgZUd3SxXgqBj.png" alt="credit: Raheel Shaikh"  /><em>credit: Raheel Shaikh</em></p>
<p>By seeing when this validation accuracy goes down, we can get a pretty good idea of when our model begins to overfit on our data, and stop the training before this happens. In training our model, we will use 5-fold 

<a href="https://towardsdatascience.com/cross-validation-explained-evaluating-estimator-performance-e51e5430ff85" rel="noopener">cross-validation</a>.</p>
<p>After all of this, we end with a training accuracy of 93.60% and test accuracy of 85.95%. Not bad at all!</p>
<h2 id="serving-the-model">Serving the model</h2>
<p>Great! So now we have a trained model. Can we put that in the Chrome extension now? Not quite yet…</p>
<p>Our model was written and trained with Keras (a Python Deep Learning library). Our Chrome extension is written in TypeScript. How do we get these two to work together?</p>
<p>Luckily for us, Tensorflow.js exists! This library allows us to run Tensorflow models from within JavaScript. Tensorflow has released a script that lets us to convert a Keras model into something that Tensorflow.js understands, so we can run that to convert our models.</p>
<p>However, we can’t just directly plug-and-play. You may remember that we did all of that data preprocessing before we trained our model. Tensorflow.js doesn’t have any of this built in, so we made our own implementation of it. You can check it out 

<a href="https://github.com/jackyzha0/reflect-chrome/blob/master/src/nn.ts" rel="noopener">here</a>.</p>
<p>We’ll leave all the technical code out (if you’re interested, feel free to peek around the source code!), but we’ve abstracted it enough that classifying an intent is a breeze.</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-typescript" data-lang="typescript"><span class="c1">// declared somewhere earlier
</span><span class="c1"></span><span class="kr">const</span> <span class="nx">model</span>: <span class="kt">nn.IntentClassifier</span> <span class="o">=</span> <span class="k">new</span> <span class="nx">nn</span><span class="p">.</span><span class="nx">IntentClassifier</span><span class="p">(</span><span class="s2">&#34;acc85.95&#34;</span><span class="p">);</span> <span class="c1">// name of converted model
</span><span class="c1"></span>
<span class="c1">// send to nlp model for prediction
</span><span class="c1"></span><span class="kr">const</span> <span class="nx">valid</span>: <span class="kt">boolean</span> <span class="o">=</span> <span class="k">await</span> <span class="nx">model</span><span class="p">.</span><span class="nx">predict</span><span class="p">(</span><span class="nx">intent</span><span class="p">);</span>
<span class="k">if</span> <span class="p">(</span><span class="nx">valid</span><span class="p">)</span> <span class="p">{</span>
    <span class="c1">// let through
</span><span class="c1"></span><span class="p">}</span> <span class="k">else</span> <span class="p">{</span>
    <span class="c1">// block page
</span><span class="c1"></span><span class="p">}</span>
</code></pre></td></tr></table>
</div>
</div><h2 id="future-improvement">Future improvement</h2>
<h3 id="possible-models">Possible models</h3>
<p>We have thought about using something more established and complex like 

<a href="https://arxiv.org/abs/1810.04805" rel="noopener">BERT</a> and retraining it on our dataset, however then comes the problem of runtime and memory usage.</p>
<p>BERT is a huge model. If you thought 150 thousand parameters was a lot, wait till you see BERT’s 110 <em>million</em> parameters. This bad boy takes a few hundred times longer and many times more memory than our current model. While yes BERT may perform really well, we just don’t think it has a place inside of a Chrome extension.</p>
<p>Our model is decently robust as it is, especially considering the entire model is &lt;2MB and takes less than 200ms to run in browser. For now, we will stick with lightweight models, but we may switch if we find a better match in the future :)</p>
<h3 id="misclassifications">Misclassifications</h3>
<p>Of course, this algorithm isn’t perfect. It does have a lot of flaws and weaknesses that we find every day, and we’re working to fix those! If there are any misclassifications that you find in the algorithm, we love to hear about it on our feedback form: 

<a href="https://forms.gle/ctypb6FmDT9RQqjv6" rel="noopener">https://forms.gle/ctypb6FmDT9RQqjv6</a>.</p>
<h2 id="closing">Closing</h2>
<p>This NLP model is at the core of reflect. It is this model’s goal to predict whether user intents are valid or not. As a result, we need to make sure this algorithm is accurate, fast, and lightweight. Hopefully, through this blog post, you’ve learned a little about how we went about building a model to fulfill those requirements.</p>
<p>Learn more about us on our website! ✨ 

<a href="http://getreflect.app/" rel="noopener">http://getreflect.app/</a></p>
<p>If you have any further questions about reflect or this NLP model, feel free to shoot us an email at 


<a href="/mailtohellogetreflect.app" rel="noopener" class="internal-link" data-src="/mailtohellogetreflect.app">hello@getreflect.app</a></p>


    </article>
    <hr/>
<div class="page-end">
    <div class="backlinks-container">
        <h3>Backlinks</h3>
<ul class="backlinks">
    
    
    
    
    
    
    
    <li>
            <a href="/thoughts/digital-mindfulness">Digital Mindfulness</a>
        </li><li>
            <a href="/thoughts/search">Search</a>
        </li>
</ul>

    </div>
    <div>
        <script src="https://cdn.jsdelivr.net/npm/d3@6"></script>
<h3>Interactive Graph</h3>
<div id="graph-container"></div>
<style>
    :root {
        --g-node: var(--secondary);
        --g-node-active: var(--primary);
        --g-node-inactive: var(--visited);
        --g-link: var(--outlinegray);
        --g-link-active: #5a7282;
    }
</style>
<script>
async function run() {
  const { index, links, content } = await fetchData()
  const curPage = "/posts/reflect"
  const pathColors = [{"/moc":"#4388cc"}]
  let depth =  1 

  const parseIdsFromLinks = (links) => [...(new Set(links.flatMap(link => ([link.source, link.target]))))]

  const neighbours = new Set()
  const wl = [curPage || "/", "__SENTINEL"]
  if (depth >= 0) {
    while (depth >= 0 && wl.length > 0) {
      
      const cur = wl.shift()
      if (cur === "__SENTINEL") {
        depth--
        wl.push("__SENTINEL")
      } else {
        neighbours.add(cur)
        const outgoing = index.links[cur] || []
        const incoming = index.backlinks[cur] || []
        wl.push(...outgoing.map(l => l.target), ...incoming.map(l => l.source))
      }
    }
  } else {
    parseIdsFromLinks(links).forEach(id => neighbours.add(id))
  }

  const data = {
    nodes: [...neighbours].map(id => ({id})),
    links: links.filter(l => neighbours.has(l.source) && neighbours.has(l.target)),
  }

  const color = (d) => {
    if (d.id === curPage || (d.id === "/" && curPage === "")) {
      return "var(--g-node-active)"
    }

    for (const pathColor of pathColors) {
      const path = Object.keys(pathColor)[0]
      const colour = pathColor[path]
      if (d.id.startsWith(path)) {
        return colour
      }
    }

    return "var(--g-node)"
  }

  const drag = simulation => {
    function dragstarted(event, d) {
      if (!event.active) simulation.alphaTarget(1).restart();
      d.fx = d.x;
      d.fy = d.y;
    }

    function dragged(event,d) {
      d.fx = event.x;
      d.fy = event.y;
    }

    function dragended(event,d) {
      if (!event.active) simulation.alphaTarget(0);
      d.fx = null;
      d.fy = null;
    }

    const enableDrag =  true 
    const noop = () => {}
    return d3.drag()
      .on("start", enableDrag ? dragstarted : noop)
      .on("drag", enableDrag ? dragged : noop)
      .on("end", enableDrag ? dragended : noop);
  }

  const height = 250
  const width = document.getElementById("graph-container").offsetWidth

  const simulation = d3.forceSimulation(data.nodes)
    .force("charge", d3.forceManyBody().strength(-30))
    .force("link", d3.forceLink(data.links).id(d => d.id))
    .force("center", d3.forceCenter());

  const svg = d3.select('#graph-container')
    .append('svg')
    .attr('width', width)
    .attr('height', height)
    .attr("viewBox", [-width / 2, -height / 2, width, height]);

  
  const enableLegend =  false 
  if (enableLegend) {
    const legend = [
      {"Current": "var(--g-node-active)"},
      {"Note": "var(--g-node)"},
      ...pathColors
    ]
    legend.forEach((legendEntry, i) => {
      const key = Object.keys(legendEntry)[0]
      const colour = legendEntry[key]
      svg.append("circle").attr("cx", -width/2 + 20).attr("cy", height/2 - 30 * (i+1)).attr("r", 6).style("fill", colour)
      svg.append("text").attr("x", -width/2 + 40).attr("y", height/2 - 30 * (i+1)).text(key).style("font-size", "15px").attr("alignment-baseline","middle")
    })
  }

  
  const link = svg.append("g")
    .selectAll("line")
    .data(data.links)
    .join("line")
    .attr("class", "link")
    .attr("stroke", "var(--g-link)")
    .attr("stroke-width", 2)
    .attr("data-source", d => d.source.id)
    .attr("data-target", d => d.target.id)

  
  const graphNode = svg.append("g")
    .selectAll("g")
    .data(data.nodes)
    .enter().append("g")

  
  const node = graphNode.append("circle")
    .attr("class", "node")
    .attr("id", (d) => d.id)
    .attr("r", (d) => {
      const numOut = index.links[d.id]?.length || 0
      const numIn = index.backlinks[d.id]?.length || 0
      return 2 + (numOut + numIn) / 4
    })
    .attr("fill", color)
    .style("cursor", "pointer")
    .on("click", (_, d) => {
      window.location.href = "https://jzhao.xyz/" + decodeURI(d.id).replace(/[\s_]+/g, '-')
    })
    .on("mouseover", function (_, d) {
      d3.selectAll(".node")
        .transition()
        .duration(100)
        .attr("fill", "var(--g-node-inactive)")

      const neighbours = parseIdsFromLinks([...(index.links[d.id] || []), ...(index.backlinks[d.id] || [])])
      const neighbourNodes = d3.selectAll(".node").filter(d => neighbours.includes(d.id))
      const currentId = d.id
      const linkNodes = d3.selectAll(".link").filter(d => d.source.id === currentId || d.target.id === currentId)

      
      neighbourNodes
        .transition()
        .duration(200)
        .attr("fill", color)

      
      linkNodes
        .transition()
        .duration(200)
        .attr("stroke", "var(--g-link-active)")

      
      d3.select(this.parentNode)
        .select("text")
        .raise()
        .transition()
        .duration(200)
        .style("opacity", 1)
    }).on("mouseleave", function (_,d) {
      d3.selectAll(".node")
        .transition()
        .duration(200)
        .attr("fill", color)

      const currentId = d.id
      const linkNodes = d3.selectAll(".link").filter(d => d.source.id === currentId || d.target.id === currentId)

      linkNodes
        .transition()
        .duration(200)
        .attr("stroke", "var(--g-link)")

      d3.select(this.parentNode)
        .select("text")
        .transition()
        .duration(200)
        .style("opacity", 0)
    })
    .call(drag(simulation));

  
  const labels = graphNode.append("text")
    .attr("dx", 12)
    .attr("dy", ".35em")
    .text((d) => content[decodeURI(d.id).replace(/[\s_]+/g, '-')]?.title || "Untitled")
    .style("opacity", 0)
    .style("pointer-events", "none")
    .call(drag(simulation));

  
  const enableZoom =  false 
  if (enableZoom) {
    svg.call(d3.zoom()
      .extent([[0, 0], [width, height]])
      .scaleExtent([0.25, 2])
      .on("zoom", ({transform}) => {
        link.attr("transform", transform);
        node.attr("transform", transform);
        labels.attr("transform", transform);
      }));
  }

  
  simulation.on("tick", () => {
    link
      .attr("x1", d => d.source.x)
      .attr("y1", d => d.source.y)
      .attr("x2", d => d.target.x)
      .attr("y2", d => d.target.y);
    node
      .attr("cx", d => d.x)
      .attr("cy", d => d.y);
    labels
      .attr("x", d => d.x)
      .attr("y", d => d.y);
  });
}

run()
</script>

    </div>
</div>


<div id="contact_buttons">
    <footer>
        <p>Made by Jacky Zhao using <a href="https://github.com/jackyzha0/quartz">Quartz</a>, © 2022</p>
        
        <a href="/">Home</a>
        <a href="https://twitter.com/_jzhao">Twitter</a><a href="https://github.com/jackyzha0">Github</a></footer>
</div>
</div>
</body>

</html>
